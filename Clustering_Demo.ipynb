{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering Demo\n",
    "### To run all the code click on 'Cell' on the toolbar at the top of the page and select 'Run All'\n",
    "You will be prompted to enter a password to unlock the data file. Your coach can provide that password.\n",
    "\n",
    "\n",
    "## <span style=\"color:blue\">There are 10 questions below, after running the code answer the questions in blue or discuss with your team</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load python libraries\n",
    "This section will load data packages which bring in prewritten code to make the clustering more simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the necessary packages\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "from yellowbrick.cluster import InterclusterDistance\n",
    "from yellowbrick.cluster import SilhouetteVisualizer\n",
    "from yellowbrick.model_selection import FeatureImportances\n",
    "\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import getpass\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "print(\"Everything was loaded correctly\")\n",
    "\n",
    "#Enter the password to access the data\n",
    "str_pwd = getpass.getpass('Enter the password to access the data:  ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open data files\n",
    "This section unlocks the data and makes it ready to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">1. Look at all the columns what kind of data are you using to cluster?</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open the encrypted zipfile\n",
    "with ZipFile('clustering_file.zip') as zf:\n",
    "    zf.extractall(pwd=bytes(str_pwd,'utf-8'))\n",
    "    \n",
    "#decrypt the file\n",
    "df_data = pd.read_csv('clustering_file.csv')\n",
    "\n",
    "#get list of features to use in visualizations\n",
    "lst_features = df_data.columns.tolist()\n",
    "print(\"data file was loaded correctly\")\n",
    "\n",
    "#View a sample of the data loaded in\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table above shows all the data points (features) we will use in clustering. Scroll right to look at the types of features we're using in the clustering project. \n",
    "\n",
    "    -There are 503 features (the number of columns)\n",
    "    -There are 788 stores in this sample dataset although we're just showing the first 5 stores in the file (rows)\n",
    "\n",
    "The numbers showing are already prepared for data science use. These are the index of the column for the store compared to all the other stores. They are normalized in a 0-1 view so we can compare across features. a 1 means that the feature is the top index for that feature for that store."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">2. How many clusters do you think we should use?</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The biggest question is how many clusters we should use. One way we use to find the optimal number of clusters is to use an elbow plot. If the plot looks like an arm, then the elbow on the arm is optimal number of clusters. A vertical line will be drawn for the optimal statistical count of clusters \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how many clusters do you want to see on the list?\n",
    "max_clusters=10\n",
    "\n",
    "X = np.array(df_data)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "visualizer = KElbowVisualizer(KMeans(), k=(1,max_clusters), size=(900,600))\n",
    "visualizer.fit(X_scaled) # Fit the data to the visualizer\n",
    "visualizer.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below will run the actual clustering for 2, 4, 7,and 10 cluster groups. Use the graph above to help determine what is the optimal number of clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating 4 different clustering views\n",
    "model_2 = KMeans(n_clusters = 2, init = \"k-means++\", max_iter = 300, n_init = 10, random_state = 0)\n",
    "model_4 = KMeans(n_clusters = 4, init = \"k-means++\", max_iter = 300, n_init = 10, random_state = 0)\n",
    "model_7 = KMeans(n_clusters = 7, init = \"k-means++\", max_iter = 300, n_init = 10, random_state = 0)\n",
    "model_10 = KMeans(n_clusters = 10, init = \"k-means++\", max_iter = 300, n_init = 10, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">3. Which clustering option would you pick based on the bar plot view and why?</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bar plot view\n",
    "These show the count of stores in each cluster. You want to make sure that the number of stores in each cluster have a good distribution. If one cluster has all the stores that probably means you need more clusters. Which clustering option do you think looks best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bar plots\n",
    "def viz_bar_plot(str_model, int_cluster):\n",
    "    ax = sns.countplot(str_model.fit_predict(X_scaled))\n",
    "    for p in ax.patches:\n",
    "            ax.annotate('{:1}'.format(p.get_height()), (p.get_x()+.3, p.get_height()+2))\n",
    "    plt.title(str(int_cluster) + ' cluster')\n",
    "    ax.set(ylabel='# of Stores', xlabel='Clusters')\n",
    "    plt.show()\n",
    "    \n",
    "viz_bar_plot(model_2, 2)\n",
    "viz_bar_plot(model_4, 4)\n",
    "viz_bar_plot(model_7, 7)\n",
    "viz_bar_plot(model_10, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">4. Which clustering option would you pick based on the silhouette view and why?</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Silhouette Visualizer\n",
    "The score is computed by averaging the silhouette coefficient for each sample, computed as the difference between the average intra-cluster distance and the mean nearest-cluster distance for each sample, normalized by the maximum value. This produces a score between 1 and -1, where 1 is highly dense clusters and -1 is completely incorrect clustering.\n",
    "\n",
    "You're looking for the best option between:\n",
    "\t- Largest average silhouette score (dotted red line)\n",
    "    - Smallest width of each cluster\n",
    "    - Least amount of negative silhouette coefficient values (lines moving left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def viz_Silhouette(str_model):\n",
    "    visualizer = SilhouetteVisualizer(str_model, colors='yellowbrick',\n",
    "                                      size=(720,480))\n",
    "    visualizer.fit(X_scaled)        # Fit the data to the visualizer\n",
    "    visualizer.ax.set_ylabel(\"silhouette coefficient values. Score = \")\n",
    "    print(str(visualizer.n_clusters_) + \" Clusters Silhouette Plot Score = \" + str(\"{:.2f}\".format(visualizer.silhouette_score_)))\n",
    "    visualizer.show()        # Finalize and render the figure\n",
    "\n",
    "viz_Silhouette(model_2)\n",
    "viz_Silhouette(model_4)\n",
    "viz_Silhouette(model_7)\n",
    "viz_Silhouette(model_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">5. Which clustering option would you pick based on the intercluster distance map and why?</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intercluster Distance Map\n",
    "Intercluster distance maps display an embedding of the cluster centers in 2 dimensions with the distance to other centers preserved. E.g. the closer to centers are in the visualization, the closer they are in the original feature space. The clusters are sized according to a scoring metric. This gives a sense of the relative importance of clusters.\n",
    "\n",
    "You're looking for clusters that do not overlap and are further apart, meaning that they are more unique.\n",
    "\n",
    "The legend in the bottom right hand corner shows the total size of the clusters (like the bar plots) and the size is how important the clusters are for the top 2 features shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Instantiate the clustering model and visualizer\n",
    "def viz_InterCluster(str_model, int_cluster):\n",
    "    visualizer = InterclusterDistance(str_model, size=(600,600),\n",
    "                                     title=\"KMeans Intercluster map for \" + str(int_cluster) + \" cluster model\")\n",
    "    visualizer.fit(X_scaled)        # Fit the data to the visualizer\n",
    "    visualizer.show()        # Finalize and render the figure\n",
    "\n",
    "viz_InterCluster(model_2, 2)\n",
    "viz_InterCluster(model_4, 4)\n",
    "viz_InterCluster(model_7, 7)\n",
    "viz_InterCluster(model_10, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">6. Using all of information from above, which clustering option do you choose?</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">7. What insights can you find about the clustering you chose? </span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What features are important to the clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The figure below shows the features ranked according to the explained variance each feature contributes to the model. In this case the features are plotted against their relative importance, that is the percent importance of the most important feature.\n",
    "\n",
    "You can see what featured matter most for each cluster model. Do some features seem more important than others? Does one of the clustering views use features that seem more realistic to you?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def viz_FeatureImportance(str_model, int_feat, int_cluster): \n",
    "    model_forest = RandomForestClassifier(n_estimators=10, random_state=13)\n",
    "    viz = FeatureImportances(model_forest,\n",
    "                             labels=lst_features,\n",
    "                             topn=int_feat,\n",
    "                             size=(720,1080),\n",
    "                             title=\"Top \" + str(int_feat) +\" features for \" + str(int_cluster) + \" cluster model\")\n",
    "    viz.fit(X_scaled, str_model.fit_predict(X_scaled))\n",
    "    viz.show()\n",
    "\n",
    "int_feat = 20\n",
    "\n",
    "viz_FeatureImportance(model_2, int_feat, 2)\n",
    "viz_FeatureImportance(model_4, int_feat, 4)\n",
    "viz_FeatureImportance(model_7, int_feat, 7)\n",
    "viz_FeatureImportance(model_10, int_feat, 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chart below shows which features are important and the importance for each of the clusters. \n",
    "\n",
    "    -Positive side (right side), the feature  is a good indicator (positively correlates) as an attribute of that cluster.\n",
    "    -Negative side (left side), the feature  is a bad indicator (negatively correlates) as an attribute of that cluster.\n",
    "    \n",
    "If you have too few clusters, not enough data is available and the visualization can't be generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def viz_FeatureRegression(str_model, int_feat, int_cluster):\n",
    "    model_regression = LogisticRegression(multi_class=\"auto\", solver=\"liblinear\")\n",
    "    viz = FeatureImportances(model_regression, \n",
    "                             stack=True, \n",
    "                             labels=lst_features,\n",
    "                             relative=False, \n",
    "                             topn=int_feat, \n",
    "                             size=(720,1080),\n",
    "                            title=\"Top \" + str(int_feat) +\" features for \" + str(int_cluster) + \" cluster model\")\n",
    "    viz.fit(X_scaled, str_model.fit_predict(X_scaled))\n",
    "    viz.show()\n",
    "\n",
    "try:\n",
    "    viz_FeatureRegression(model_2, int_feat, 2)\n",
    "except:\n",
    "    print(\"Not enough data to show for 2 cluster model\")\n",
    "try:\n",
    "    viz_FeatureRegression(model_4, int_feat, 4)\n",
    "except:\n",
    "    print(\"Not enough data to show for 4 cluster model\")\n",
    "try:\n",
    "    viz_FeatureRegression(model_7, int_feat, 7)\n",
    "except:\n",
    "    print(\"Not enough data to show for 7 cluster model\")\n",
    "try:\n",
    "    viz_FeatureRegression(model_10, int_feat, 10)\n",
    "except:\n",
    "    print(\"Not enough data to show for 10 cluster model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">8. Share your cluster choice and insights with your group, where did your team agree and where did you differ? </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">9. What did you learn about clustering? </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">10. How could you use clustering in your areas? </span>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "413.75px",
    "left": "994.578px",
    "right": "20px",
    "top": "142.922px",
    "width": "437.516px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
